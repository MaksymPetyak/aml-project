{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.layers import Conv2D, Dropout, Dense, MaxPool2D\n",
    "from tensorflow.keras.layers import Input, LeakyReLU, Softmax, Reshape, Flatten\n",
    "from tensorflow.keras.layers import concatenate, maximum, Lambda, Layer\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, GlobalMaxPooling2D\n",
    "import tensorflow.keras.backend as K\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Additional layers not available in core Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Bias(Layer):\n",
    "    \"\"\"\n",
    "    Adds bias to a layer. This is used for untied biases convolution. \n",
    "    \"\"\"\n",
    "    def __init__(self, **kwargs):\n",
    "        super(Bias, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        # Create a trainable weight variable for this layer.\n",
    "        self.bias = self.add_weight(name='bias', \n",
    "                                      shape=input_shape[1:],\n",
    "                                      initializer='uniform',\n",
    "                                      trainable=True)\n",
    "        super(Bias, self).build(input_shape)  # Be sure to call this at the end\n",
    "\n",
    "    def call(self, x):\n",
    "        return tf.add(x, self.bias)\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_pool_max(input, pool_size=2, axis=1):\n",
    "    \"\"\"\n",
    "    Based on lasagne implementation of FeaturePool\n",
    "    \"\"\"\n",
    "    input_shape = input.shape.as_list()\n",
    "    num_feature_maps = input_shape[axis]\n",
    "    num_feature_maps_out = num_feature_maps // pool_size\n",
    "    \n",
    "    pool_shape = tf.TensorShape(\n",
    "        (input_shape[1:axis] + [num_feature_maps_out, pool_size] + input_shape[axis+1:])\n",
    "    )\n",
    "    \n",
    "    print(pool_shape)\n",
    "    input_reshaped = Reshape(pool_shape)(input)\n",
    "    # reduce along all axis but the target one\n",
    "    reduction_axis = list(range(1, len(pool_shape)+1))\n",
    "    reduction_axis.pop(axis-1)\n",
    "    \n",
    "    return tf.reduce_max(input_reshaped, axis=reduction_axis)\n",
    "\n",
    "# create Layer for reshape with batchsize\n",
    "# strong_reshape_func = lambda x: tf.reshape(x, (batch_size//2, concat.shape[1]*2))\n",
    "# StrongReshape = Lambda(strong_reshape_func)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building the main model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(width=512, height=512, filename=None,\n",
    "                n_classes=5, batch_size=64, p_conv=0.0):\n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"\n",
    "    # Input shape (height, width, depth), different from original implimentation\n",
    "    main_input = Input(shape=(height, width, 3),\n",
    "                       batch_size=batch_size,\n",
    "                      )\n",
    "    \n",
    "    # Note: for conv layers paper uses untie_biases=True\n",
    "    # layer will have separate bias parameters for each position in each channel. \n",
    "    # As a result, the b attribute will be a 3D tensor.\n",
    "\n",
    "    # no need to init weights as they will be loaded from a file\n",
    "    # Conv layers(filters, kernel_size)\n",
    "    conv_main_1 = Conv2D(32, 7, strides=(2, 2), padding='same', \n",
    "                    use_bias=False,\n",
    "                    activation= None,\n",
    "                   )(main_input)\n",
    "    conv_bias_1 = Bias()(conv_main_1)\n",
    "    conv_activation_1 = LeakyReLU(alpha=0.5)(conv_bias_1)\n",
    "    dropout_1 = Dropout(p_conv)(conv_activation_1)\n",
    "    maxpool_1 = MaxPool2D(pool_size=3, strides=(2, 2))(dropout_1)\n",
    "    # 3\n",
    "    conv_main_2 = Conv2D(32, 3, strides=(1, 1), padding='same', \n",
    "                         use_bias=False,\n",
    "                         activation= None,\n",
    "                        )(maxpool_1)\n",
    "    conv_bias_2 = Bias()(conv_main_2)\n",
    "    conv_activation_2 = LeakyReLU(alpha=0.5)(conv_bias_2)\n",
    "    dropout_2 = Dropout(p_conv)(conv_activation_2)\n",
    "    # 4\n",
    "    conv_main_3 = Conv2D(32, 3, strides=(1, 1), padding='same', \n",
    "                         use_bias=False,\n",
    "                         activation= None,\n",
    "                        )(dropout_2)\n",
    "    conv_bias_3 = Bias()(conv_main_3)\n",
    "    conv_activation_3 = LeakyReLU(alpha=0.5)(conv_bias_3)\n",
    "    dropout_3 = Dropout(p_conv)(conv_activation_3)\n",
    "    maxpool_3 = MaxPool2D(pool_size=3, strides=(2, 2))(dropout_3)\n",
    "    # 6\n",
    "    conv_main_4 = Conv2D(64, 3, strides=(1, 1), padding='same', \n",
    "                         use_bias=False,\n",
    "                         activation=None,\n",
    "                        )(maxpool_3)\n",
    "    conv_bias_4 = Bias()(conv_main_4)\n",
    "    conv_activation_4 = LeakyReLU(alpha=0.5)(conv_bias_4)\n",
    "    dropout_4 = Dropout(p_conv)(conv_activation_4)\n",
    "    # 7\n",
    "    conv_main_5 = Conv2D(64, 3, strides=(1, 1), padding='same', \n",
    "                         use_bias=False,\n",
    "                         activation=None,\n",
    "                        )(dropout_4)\n",
    "    conv_bias_5 = Bias()(conv_main_5)\n",
    "    conv_activation_5 = LeakyReLU(alpha=0.5)(conv_bias_5)\n",
    "    dropout_5 = Dropout(p_conv)(conv_activation_5)\n",
    "    maxpool_5 = MaxPool2D(pool_size=3, strides=(2, 2))(dropout_5)\n",
    "    # 9 \n",
    "    conv_main_6 = Conv2D(128, 3, strides=(1, 1), padding='same', \n",
    "                         use_bias=False,\n",
    "                         activation=None,\n",
    "                        )(maxpool_5)\n",
    "    conv_bias_6 = Bias()(conv_main_6)\n",
    "    conv_activation_6 = LeakyReLU(alpha=0.5)(conv_bias_6)\n",
    "    dropout_6 = Dropout(p_conv)(conv_activation_6)\n",
    "    # 10    \n",
    "    conv_main_7 = Conv2D(128, 3, strides=(1, 1), padding='same', \n",
    "                         use_bias=False,\n",
    "                         activation=None,\n",
    "                        )(dropout_6)\n",
    "    conv_bias_7 = Bias()(conv_main_7)\n",
    "    conv_activation_7 = LeakyReLU(alpha=0.5)(conv_bias_7)\n",
    "    dropout_7 = Dropout(p_conv)(conv_activation_7)\n",
    "    # 11\n",
    "    conv_main_8 = Conv2D(128, 3, strides=(1, 1), padding='same', \n",
    "                         use_bias=False,\n",
    "                         activation=None,\n",
    "                        )(dropout_7)\n",
    "    conv_bias_8 = Bias()(conv_main_8)\n",
    "    conv_activation_8 = LeakyReLU(alpha=0.5)(conv_bias_8)\n",
    "    dropout_8 = Dropout(p_conv)(conv_activation_8)\n",
    "    # 12\n",
    "    conv_main_9 = Conv2D(128, 3, strides=(1, 1), padding='same', \n",
    "                         use_bias=False,\n",
    "                         activation=None,\n",
    "                        )(dropout_8)\n",
    "    conv_bias_9 = Bias()(conv_main_9)\n",
    "    conv_activation_9 = LeakyReLU(alpha=0.5)(conv_bias_9)\n",
    "    dropout_9 = Dropout(p_conv)(conv_activation_9)\n",
    "    maxpool_9 = MaxPool2D(pool_size=3, strides=(2, 2))(dropout_9)\n",
    "    # 14\n",
    "    conv_main_10 = Conv2D(256, 3, strides=(1, 1), padding='same', \n",
    "                         use_bias=False,\n",
    "                         activation=None,\n",
    "                        )(maxpool_9)\n",
    "    conv_bias_10 = Bias()(conv_main_10)\n",
    "    conv_activation_10 = LeakyReLU(alpha=0.5)(conv_bias_10)\n",
    "    dropout_10 = Dropout(p_conv)(conv_activation_10)\n",
    "    # 15\n",
    "    conv_main_11 = Conv2D(256, 3, strides=(1, 1), padding='same', \n",
    "                         use_bias=False,\n",
    "                         activation=None,\n",
    "                        )(dropout_10)\n",
    "    conv_bias_11 = Bias()(conv_main_11)\n",
    "    conv_activation_11 = LeakyReLU(alpha=0.5)(conv_bias_11)\n",
    "    dropout_11 = Dropout(p_conv)(conv_activation_11)\n",
    "    # 16\n",
    "    conv_main_12 = Conv2D(256, 3, strides=(1, 1), padding='same', \n",
    "                         use_bias=False,\n",
    "                         activation=None,\n",
    "                        )(dropout_11)\n",
    "    conv_bias_12 = Bias()(conv_main_12)\n",
    "    conv_activation_12 = LeakyReLU(alpha=0.5)(conv_bias_12)\n",
    "    dropout_12 = Dropout(p_conv)(conv_activation_12)\n",
    "    # 17\n",
    "    conv_main_13 = Conv2D(256, 3, strides=(1, 1), padding='same', \n",
    "                         use_bias=False,\n",
    "                         activation=None,\n",
    "                        )(dropout_12)\n",
    "    conv_bias_13 = Bias()(conv_main_13)\n",
    "    conv_activation_13 = LeakyReLU(alpha=0.5, name='layer_17')(conv_bias_13)\n",
    "    dropout_13 = Dropout(p_conv)(conv_activation_13)\n",
    "    maxpool_13 = MaxPool2D(pool_size=3, name=\"last_conv\", strides=(2, 2))(dropout_13)\n",
    "    # 19, special dropout between phases with p=1/2 \n",
    "    dropout_inter = Dropout(0.5)(maxpool_13)\n",
    "    # 20 Dense phase \n",
    "    # Begins with Maxout layer, which is implemented here as Dense+custom feature_pool function\n",
    "    flatten_inter = Flatten()(dropout_inter)\n",
    "    maxout_1 = Dense(units=1024, \n",
    "                     activation=None)(flatten_inter)\n",
    "    # need to wrap operation in Lambda to count as a layer\n",
    "    maxout_2 = Lambda(lambda x: feature_pool_max(x, pool_size=2, axis=1))(maxout_1)\n",
    "    \n",
    "    # 22 Concatenate with processed img, take both eyes into account\n",
    "    img_dim_input = Input(shape=(2,), batch_size=batch_size, name=\"imgdim\")\n",
    "    concat = concatenate([maxout_2, img_dim_input], axis=1)\n",
    "    \n",
    "    # 24\n",
    "    # flatten = Reshape((-1, concat.output_shape()[1] * 2))(concat)\n",
    "    print(concat.shape)\n",
    "    # use lambda for custom reshape that's capable of changing batch_size as well\n",
    "    # expect order left-right\n",
    "    # TODO: (-1, net['23'].output_shape[1] * 2)\n",
    "    flatten = Lambda(lambda x: K.reshape(x, (-1, concat.shape[1]*2)))(concat)\n",
    "    dense_droupout_0 = Dropout(0.5)(flatten)\n",
    "    # 26\n",
    "    dense_1 = Dense(units=1024,\n",
    "                    activation=None,\n",
    "                   )(dense_droupout_0)\n",
    "    dense_maxpool_1 = Lambda(lambda x: feature_pool_max(x, pool_size=2, axis=1))(dense_1)\n",
    "    dense_dropout_1 = Dropout(0.5)(dense_maxpool_1)\n",
    "    \n",
    "    # 29\n",
    "    dense_2 = Dense(units=n_classes*2,\n",
    "                    activation=None,\n",
    "                   )(dense_dropout_1)\n",
    "    softmax_flatten = Lambda(lambda x: tf.reshape(x, (-1, n_classes)))(dense_2)\n",
    "    softmax = keras.layers.Softmax()(softmax_flatten)\n",
    "    \n",
    "    model = Model(inputs=[main_input, img_dim_input], outputs=[softmax])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(512, 2)\n",
      "(64, 514)\n",
      "(512, 2)\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            (64, 512, 512, 3)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (64, 256, 256, 32)   4704        input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bias_26 (Bias)                  (64, 256, 256, 32)   2097152     conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_26 (LeakyReLU)      (64, 256, 256, 32)   0           bias_26[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_32 (Dropout)            (64, 256, 256, 32)   0           leaky_re_lu_26[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2D)  (64, 127, 127, 32)   0           dropout_32[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)              (64, 127, 127, 32)   9216        max_pooling2d_8[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "bias_27 (Bias)                  (64, 127, 127, 32)   516128      conv2d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_27 (LeakyReLU)      (64, 127, 127, 32)   0           bias_27[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_33 (Dropout)            (64, 127, 127, 32)   0           leaky_re_lu_27[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)              (64, 127, 127, 32)   9216        dropout_33[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "bias_28 (Bias)                  (64, 127, 127, 32)   516128      conv2d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_28 (LeakyReLU)      (64, 127, 127, 32)   0           bias_28[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_34 (Dropout)            (64, 127, 127, 32)   0           leaky_re_lu_28[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2D)  (64, 63, 63, 32)     0           dropout_34[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_29 (Conv2D)              (64, 63, 63, 64)     18432       max_pooling2d_9[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "bias_29 (Bias)                  (64, 63, 63, 64)     254016      conv2d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_29 (LeakyReLU)      (64, 63, 63, 64)     0           bias_29[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_35 (Dropout)            (64, 63, 63, 64)     0           leaky_re_lu_29[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_30 (Conv2D)              (64, 63, 63, 64)     36864       dropout_35[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "bias_30 (Bias)                  (64, 63, 63, 64)     254016      conv2d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_30 (LeakyReLU)      (64, 63, 63, 64)     0           bias_30[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_36 (Dropout)            (64, 63, 63, 64)     0           leaky_re_lu_30[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling2D) (64, 31, 31, 64)     0           dropout_36[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_31 (Conv2D)              (64, 31, 31, 128)    73728       max_pooling2d_10[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "bias_31 (Bias)                  (64, 31, 31, 128)    123008      conv2d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_31 (LeakyReLU)      (64, 31, 31, 128)    0           bias_31[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_37 (Dropout)            (64, 31, 31, 128)    0           leaky_re_lu_31[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_32 (Conv2D)              (64, 31, 31, 128)    147456      dropout_37[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "bias_32 (Bias)                  (64, 31, 31, 128)    123008      conv2d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_32 (LeakyReLU)      (64, 31, 31, 128)    0           bias_32[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_38 (Dropout)            (64, 31, 31, 128)    0           leaky_re_lu_32[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_33 (Conv2D)              (64, 31, 31, 128)    147456      dropout_38[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "bias_33 (Bias)                  (64, 31, 31, 128)    123008      conv2d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_33 (LeakyReLU)      (64, 31, 31, 128)    0           bias_33[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_39 (Dropout)            (64, 31, 31, 128)    0           leaky_re_lu_33[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_34 (Conv2D)              (64, 31, 31, 128)    147456      dropout_39[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "bias_34 (Bias)                  (64, 31, 31, 128)    123008      conv2d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_34 (LeakyReLU)      (64, 31, 31, 128)    0           bias_34[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_40 (Dropout)            (64, 31, 31, 128)    0           leaky_re_lu_34[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling2D) (64, 15, 15, 128)    0           dropout_40[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_35 (Conv2D)              (64, 15, 15, 256)    294912      max_pooling2d_11[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "bias_35 (Bias)                  (64, 15, 15, 256)    57600       conv2d_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_35 (LeakyReLU)      (64, 15, 15, 256)    0           bias_35[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_41 (Dropout)            (64, 15, 15, 256)    0           leaky_re_lu_35[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_36 (Conv2D)              (64, 15, 15, 256)    589824      dropout_41[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "bias_36 (Bias)                  (64, 15, 15, 256)    57600       conv2d_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_36 (LeakyReLU)      (64, 15, 15, 256)    0           bias_36[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_42 (Dropout)            (64, 15, 15, 256)    0           leaky_re_lu_36[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_37 (Conv2D)              (64, 15, 15, 256)    589824      dropout_42[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "bias_37 (Bias)                  (64, 15, 15, 256)    57600       conv2d_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_37 (LeakyReLU)      (64, 15, 15, 256)    0           bias_37[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_43 (Dropout)            (64, 15, 15, 256)    0           leaky_re_lu_37[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_38 (Conv2D)              (64, 15, 15, 256)    589824      dropout_43[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "bias_38 (Bias)                  (64, 15, 15, 256)    57600       conv2d_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "layer_17 (LeakyReLU)            (64, 15, 15, 256)    0           bias_38[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_44 (Dropout)            (64, 15, 15, 256)    0           layer_17[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "last_conv (MaxPooling2D)        (64, 7, 7, 256)      0           dropout_44[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_45 (Dropout)            (64, 7, 7, 256)      0           last_conv[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)             (64, 12544)          0           dropout_45[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (64, 1024)           12846080    flatten_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_8 (Lambda)               (64, 512)            0           dense_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "imgdim (InputLayer)             (64, 2)              0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (64, 514)            0           lambda_8[0][0]                   \n",
      "                                                                 imgdim[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_9 (Lambda)               (32, 1028)           0           concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_46 (Dropout)            (32, 1028)           0           lambda_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (32, 1024)           1053696     dropout_46[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_10 (Lambda)              (32, 512)            0           dense_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_47 (Dropout)            (32, 512)            0           lambda_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Dense)                 (32, 10)             5130        dropout_47[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_11 (Lambda)              (64, 5)              0           dense_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "softmax_3 (Softmax)             (64, 5)              0           lambda_11[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 20,923,690\n",
      "Trainable params: 20,923,690\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = build_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to unicode compatability issues between python2 and python3 we use np.save method, with encoding as 'bytes'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_names = ['Conv_1_W', 'Conv_1_b', 'Conv_2_W', 'Conv_2_b', 'Conv_3_W', 'Conv_3_b', \n",
    "                'Conv_4_W', 'Conv_4_b', 'Conv_5_W', 'Conv_5_b', 'Conv_6_W', 'Conv_6_b', \n",
    "                'Conv_7_W', 'Conv_7_b', 'Conv_8_W', 'Conv_8_b', 'Conv_9_W', 'Conv_9_b', \n",
    "                'Conv_10_W', 'Conv_10_b', 'Conv_11_W', 'Conv_11_b', 'Conv_12_W', 'Conv_12_b', \n",
    "                'Conv_13_W', 'Conv_13_b', 'Dense_1_W', 'Dense_1_b', 'Dense_2_W', 'Dense_2_b', \n",
    "                'Dense_3_W', 'Dense_3_b']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = np.load(\"../models/JFnet_weights.npy\", encoding=\"bytes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.5916246 ,  0.04647866,  0.40189323, -0.12301593, -0.41697878,\n",
       "        0.6376505 ,  0.02411902,  0.393416  , -0.03656115, -0.51861304],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer_to_weights = dict(zip(params_names, arr))\n",
    "layer_to_weights['Dense_3_b']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Layer weight shape (512, 2) not compatible with provided weight shape (12544, 1024)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-41-1dbbd42acb2c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m             \u001b[0mc_dense\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m \u001b[0mupdate_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayer_to_weigts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-41-1dbbd42acb2c>\u001b[0m in \u001b[0;36mupdate_weights\u001b[0;34m(model, layer_to_weights)\u001b[0m\n\u001b[1;32m     18\u001b[0m             layer.set_weights([\n\u001b[1;32m     19\u001b[0m                 \u001b[0mlayer_to_weights\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Dense_{}_W'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc_dense\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m                 \u001b[0mlayer_to_weights\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Dense_{}_b'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc_dense\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m             ])\n\u001b[1;32m     22\u001b[0m             \u001b[0mc_dense\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36mset_weights\u001b[0;34m(self, weights)\u001b[0m\n\u001b[1;32m    832\u001b[0m         raise ValueError('Layer weight shape ' + str(pv.shape) +\n\u001b[1;32m    833\u001b[0m                          \u001b[0;34m' not compatible with '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 834\u001b[0;31m                          'provided weight shape ' + str(w.shape))\n\u001b[0m\u001b[1;32m    835\u001b[0m       \u001b[0mweight_value_tuples\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    836\u001b[0m     \u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_set_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight_value_tuples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Layer weight shape (512, 2) not compatible with provided weight shape (12544, 1024)"
     ]
    }
   ],
   "source": [
    "def update_weights(model, layer_to_weights):\n",
    "    # set all layers in the model\n",
    "    c_conv = 1\n",
    "    c_dense = 1\n",
    "    # lasagne store weights not their transpose, so we transpose\n",
    "    for layer in model.layers:\n",
    "        layer_str = str(layer)\n",
    "        if \"Conv2D\" in layer_str:\n",
    "            layer.set_weights([\n",
    "                layer_to_weights['Conv_{}_W'.format(c_conv)].T\n",
    "            ])\n",
    "        if \"Bias\" in layer_str:\n",
    "            layer.set_weights([\n",
    "                layer_to_weights['Conv_{}_b'.format(c_conv)].T\n",
    "            ])\n",
    "            c_conv +=1\n",
    "        if \"Dense\" in layer_str:\n",
    "            layer.set_weights([\n",
    "                layer_to_weights['Dense_{}_W'.format(c_dense)],\n",
    "                layer_to_weights['Dense_{}_b'.format(c_dense)]\n",
    "            ])\n",
    "            c_dense += 1\n",
    "\n",
    "update_weights(model, layer_to_weigts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save models with these weights for future use in the class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.save_weights(\"../models/keras_JFnet.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(512, 2)\n",
      "(64, 514)\n",
      "(512, 2)\n"
     ]
    }
   ],
   "source": [
    "model2 = build_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(64, 512, 512, 3), (64, 2)]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.29261371, 0.26478586, 0.3295034 , 0.0867935 , 0.02630354],\n",
       "       [0.30382672, 0.26224723, 0.3291842 , 0.08550265, 0.01923905],\n",
       "       [0.29261371, 0.26478586, 0.3295034 , 0.0867935 , 0.02630354],\n",
       "       [0.30382672, 0.26224723, 0.3291842 , 0.08550265, 0.01923905],\n",
       "       [0.29261371, 0.26478586, 0.3295034 , 0.0867935 , 0.02630354],\n",
       "       [0.30382672, 0.26224723, 0.3291842 , 0.08550265, 0.01923905],\n",
       "       [0.29261371, 0.26478586, 0.3295034 , 0.0867935 , 0.02630354],\n",
       "       [0.30382672, 0.26224723, 0.3291842 , 0.08550265, 0.01923905],\n",
       "       [0.29261371, 0.26478586, 0.3295034 , 0.0867935 , 0.02630354],\n",
       "       [0.30382672, 0.26224723, 0.3291842 , 0.08550265, 0.01923905],\n",
       "       [0.29261371, 0.26478586, 0.3295034 , 0.0867935 , 0.02630354],\n",
       "       [0.30382672, 0.26224723, 0.3291842 , 0.08550265, 0.01923905],\n",
       "       [0.29261371, 0.26478586, 0.3295034 , 0.0867935 , 0.02630354],\n",
       "       [0.30382672, 0.26224723, 0.3291842 , 0.08550265, 0.01923905],\n",
       "       [0.29261371, 0.26478586, 0.3295034 , 0.0867935 , 0.02630354],\n",
       "       [0.30382672, 0.26224723, 0.3291842 , 0.08550265, 0.01923905],\n",
       "       [0.29261371, 0.26478586, 0.3295034 , 0.0867935 , 0.02630354],\n",
       "       [0.30382672, 0.26224723, 0.3291842 , 0.08550265, 0.01923905],\n",
       "       [0.29261371, 0.26478586, 0.3295034 , 0.0867935 , 0.02630354],\n",
       "       [0.30382672, 0.26224723, 0.3291842 , 0.08550265, 0.01923905],\n",
       "       [0.29261371, 0.26478586, 0.3295034 , 0.0867935 , 0.02630354],\n",
       "       [0.30382672, 0.26224723, 0.3291842 , 0.08550265, 0.01923905],\n",
       "       [0.29261371, 0.26478586, 0.3295034 , 0.0867935 , 0.02630354],\n",
       "       [0.30382672, 0.26224723, 0.3291842 , 0.08550265, 0.01923905],\n",
       "       [0.29261371, 0.26478586, 0.3295034 , 0.0867935 , 0.02630354],\n",
       "       [0.30382672, 0.26224723, 0.3291842 , 0.08550265, 0.01923905],\n",
       "       [0.29261371, 0.26478586, 0.3295034 , 0.0867935 , 0.02630354],\n",
       "       [0.30382672, 0.26224723, 0.3291842 , 0.08550265, 0.01923905],\n",
       "       [0.29261371, 0.26478586, 0.3295034 , 0.0867935 , 0.02630354],\n",
       "       [0.30382672, 0.26224723, 0.3291842 , 0.08550265, 0.01923905],\n",
       "       [0.29261371, 0.26478586, 0.3295034 , 0.0867935 , 0.02630354],\n",
       "       [0.30382672, 0.26224723, 0.3291842 , 0.08550265, 0.01923905],\n",
       "       [0.29261371, 0.26478586, 0.3295034 , 0.0867935 , 0.02630354],\n",
       "       [0.30382672, 0.26224723, 0.3291842 , 0.08550265, 0.01923905],\n",
       "       [0.29261371, 0.26478586, 0.3295034 , 0.0867935 , 0.02630354],\n",
       "       [0.30382672, 0.26224723, 0.3291842 , 0.08550265, 0.01923905],\n",
       "       [0.29261371, 0.26478586, 0.3295034 , 0.0867935 , 0.02630354],\n",
       "       [0.30382672, 0.26224723, 0.3291842 , 0.08550265, 0.01923905],\n",
       "       [0.29261371, 0.26478586, 0.3295034 , 0.0867935 , 0.02630354],\n",
       "       [0.30382672, 0.26224723, 0.3291842 , 0.08550265, 0.01923905],\n",
       "       [0.29261371, 0.26478586, 0.3295034 , 0.0867935 , 0.02630354],\n",
       "       [0.30382672, 0.26224723, 0.3291842 , 0.08550265, 0.01923905],\n",
       "       [0.29261371, 0.26478586, 0.3295034 , 0.0867935 , 0.02630354],\n",
       "       [0.30382672, 0.26224723, 0.3291842 , 0.08550265, 0.01923905],\n",
       "       [0.29261371, 0.26478586, 0.3295034 , 0.0867935 , 0.02630354],\n",
       "       [0.30382672, 0.26224723, 0.3291842 , 0.08550265, 0.01923905],\n",
       "       [0.29261371, 0.26478586, 0.3295034 , 0.0867935 , 0.02630354],\n",
       "       [0.30382672, 0.26224723, 0.3291842 , 0.08550265, 0.01923905],\n",
       "       [0.29261371, 0.26478586, 0.3295034 , 0.0867935 , 0.02630354],\n",
       "       [0.30382672, 0.26224723, 0.3291842 , 0.08550265, 0.01923905],\n",
       "       [0.29261371, 0.26478586, 0.3295034 , 0.0867935 , 0.02630354],\n",
       "       [0.30382672, 0.26224723, 0.3291842 , 0.08550265, 0.01923905],\n",
       "       [0.29261371, 0.26478586, 0.3295034 , 0.0867935 , 0.02630354],\n",
       "       [0.30382672, 0.26224723, 0.3291842 , 0.08550265, 0.01923905],\n",
       "       [0.29261371, 0.26478586, 0.3295034 , 0.0867935 , 0.02630354],\n",
       "       [0.30382672, 0.26224723, 0.3291842 , 0.08550265, 0.01923905],\n",
       "       [0.29261371, 0.26478586, 0.3295034 , 0.0867935 , 0.02630354],\n",
       "       [0.30382672, 0.26224723, 0.3291842 , 0.08550265, 0.01923905],\n",
       "       [0.29261371, 0.26478586, 0.3295034 , 0.0867935 , 0.02630354],\n",
       "       [0.30382672, 0.26224723, 0.3291842 , 0.08550265, 0.01923905],\n",
       "       [0.29261371, 0.26478586, 0.3295034 , 0.0867935 , 0.02630354],\n",
       "       [0.30382672, 0.26224723, 0.3291842 , 0.08550265, 0.01923905],\n",
       "       [0.29261371, 0.26478586, 0.3295034 , 0.0867935 , 0.02630354],\n",
       "       [0.30382672, 0.26224723, 0.3291842 , 0.08550265, 0.01923905]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict([np.zeros((64, 512, 512, 3)), np.zeros((64, 2))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.load_weights(\"../models/keras_JFnet.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Peeling off layers and BCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_classes=2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_output = model2.get_layer(\"layer_17\").output\n",
    "\n",
    "mean_pooled = GlobalAveragePooling2D(\n",
    "    data_format='channels_last')(conv_output)\n",
    "max_pooled = GlobalMaxPooling2D(\n",
    "    data_format='channels_last')(conv_output)\n",
    "global_pool = concatenate([mean_pooled, max_pooled], axis=1)\n",
    "\n",
    "softmax_input = Dense(\n",
    "    units=n_classes, activation=None,)(global_pool)\n",
    "softmax_output = Softmax()(softmax_input)\n",
    "\n",
    "bcnn_model = Model(inputs=[model2.input[0]], outputs=[softmax_output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_4 (InputLayer)            (64, 512, 512, 3)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_39 (Conv2D)              (64, 256, 256, 32)   4704        input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bias_39 (Bias)                  (64, 256, 256, 32)   2097152     conv2d_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_38 (LeakyReLU)      (64, 256, 256, 32)   0           bias_39[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_48 (Dropout)            (64, 256, 256, 32)   0           leaky_re_lu_38[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_12 (MaxPooling2D) (64, 127, 127, 32)   0           dropout_48[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_40 (Conv2D)              (64, 127, 127, 32)   9216        max_pooling2d_12[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "bias_40 (Bias)                  (64, 127, 127, 32)   516128      conv2d_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_39 (LeakyReLU)      (64, 127, 127, 32)   0           bias_40[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_49 (Dropout)            (64, 127, 127, 32)   0           leaky_re_lu_39[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_41 (Conv2D)              (64, 127, 127, 32)   9216        dropout_49[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "bias_41 (Bias)                  (64, 127, 127, 32)   516128      conv2d_41[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_40 (LeakyReLU)      (64, 127, 127, 32)   0           bias_41[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_50 (Dropout)            (64, 127, 127, 32)   0           leaky_re_lu_40[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_13 (MaxPooling2D) (64, 63, 63, 32)     0           dropout_50[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_42 (Conv2D)              (64, 63, 63, 64)     18432       max_pooling2d_13[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "bias_42 (Bias)                  (64, 63, 63, 64)     254016      conv2d_42[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_41 (LeakyReLU)      (64, 63, 63, 64)     0           bias_42[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_51 (Dropout)            (64, 63, 63, 64)     0           leaky_re_lu_41[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_43 (Conv2D)              (64, 63, 63, 64)     36864       dropout_51[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "bias_43 (Bias)                  (64, 63, 63, 64)     254016      conv2d_43[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_42 (LeakyReLU)      (64, 63, 63, 64)     0           bias_43[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_52 (Dropout)            (64, 63, 63, 64)     0           leaky_re_lu_42[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_14 (MaxPooling2D) (64, 31, 31, 64)     0           dropout_52[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_44 (Conv2D)              (64, 31, 31, 128)    73728       max_pooling2d_14[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "bias_44 (Bias)                  (64, 31, 31, 128)    123008      conv2d_44[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_43 (LeakyReLU)      (64, 31, 31, 128)    0           bias_44[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_53 (Dropout)            (64, 31, 31, 128)    0           leaky_re_lu_43[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_45 (Conv2D)              (64, 31, 31, 128)    147456      dropout_53[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "bias_45 (Bias)                  (64, 31, 31, 128)    123008      conv2d_45[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_44 (LeakyReLU)      (64, 31, 31, 128)    0           bias_45[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_54 (Dropout)            (64, 31, 31, 128)    0           leaky_re_lu_44[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_46 (Conv2D)              (64, 31, 31, 128)    147456      dropout_54[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "bias_46 (Bias)                  (64, 31, 31, 128)    123008      conv2d_46[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_45 (LeakyReLU)      (64, 31, 31, 128)    0           bias_46[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_55 (Dropout)            (64, 31, 31, 128)    0           leaky_re_lu_45[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_47 (Conv2D)              (64, 31, 31, 128)    147456      dropout_55[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "bias_47 (Bias)                  (64, 31, 31, 128)    123008      conv2d_47[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_46 (LeakyReLU)      (64, 31, 31, 128)    0           bias_47[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_56 (Dropout)            (64, 31, 31, 128)    0           leaky_re_lu_46[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_15 (MaxPooling2D) (64, 15, 15, 128)    0           dropout_56[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_48 (Conv2D)              (64, 15, 15, 256)    294912      max_pooling2d_15[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "bias_48 (Bias)                  (64, 15, 15, 256)    57600       conv2d_48[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_47 (LeakyReLU)      (64, 15, 15, 256)    0           bias_48[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_57 (Dropout)            (64, 15, 15, 256)    0           leaky_re_lu_47[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_49 (Conv2D)              (64, 15, 15, 256)    589824      dropout_57[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "bias_49 (Bias)                  (64, 15, 15, 256)    57600       conv2d_49[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_48 (LeakyReLU)      (64, 15, 15, 256)    0           bias_49[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_58 (Dropout)            (64, 15, 15, 256)    0           leaky_re_lu_48[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_50 (Conv2D)              (64, 15, 15, 256)    589824      dropout_58[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "bias_50 (Bias)                  (64, 15, 15, 256)    57600       conv2d_50[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_49 (LeakyReLU)      (64, 15, 15, 256)    0           bias_50[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_59 (Dropout)            (64, 15, 15, 256)    0           leaky_re_lu_49[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_51 (Conv2D)              (64, 15, 15, 256)    589824      dropout_59[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "bias_51 (Bias)                  (64, 15, 15, 256)    57600       conv2d_51[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "layer_17 (LeakyReLU)            (64, 15, 15, 256)    0           bias_51[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_2 (Glo (64, 256)            0           layer_17[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling2d_2 (GlobalM (64, 256)            0           layer_17[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_6 (Concatenate)     (64, 512)            0           global_average_pooling2d_2[0][0] \n",
      "                                                                 global_max_pooling2d_2[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_14 (Dense)                (64, 2)              1026        concatenate_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "softmax_6 (Softmax)             (64, 2)              0           dense_14[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 7,019,810\n",
      "Trainable params: 7,019,810\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "bcnn_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving bcnn models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "bcnn_param_names = ['Conv_1_W', 'Conv_1_b', 'Conv_2_W', 'Conv_2_b', 'Conv_3_W', 'Conv_3_b', \n",
    "                    'Conv_4_W', 'Conv_4_b', 'Conv_5_W', 'Conv_5_b', 'Conv_6_W', 'Conv_6_b', \n",
    "                    'Conv_7_W', 'Conv_7_b', 'Conv_8_W', 'Conv_8_b', 'Conv_9_W', 'Conv_9_b', \n",
    "                    'Conv_10_W', 'Conv_10_b', 'Conv_11_W', 'Conv_11_b', 'Conv_12_W', 'Conv_12_b', \n",
    "                    'Conv_13_W', 'Conv_13_b', 'Dense_1_W', 'Dense_1_b']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "bcnn_weights = np.load(\"../models/weights_bcnn1_392bea6.npy\", encoding=\"bytes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(bcnn_weights) == len(params_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_to_weights = dict(zip(params_names, bcnn_weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "update_weights(bcnn_model, layer_to_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "bcnn_model.save_weights(\"../models/weights_bcnn1_392bea6.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction with uncertainty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_input = np.zeros(model.input_shape)\n",
    "model2_input = [np.zeros((64, 512, 512, 3)), np.zeros((64, 2))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction with uncertainty\n",
    "f = K.function(\n",
    "    [model2.input, K.learning_phase()],\n",
    "    model2.layers[-1].output,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.39036417, 0.2853371 , 0.23163301, 0.0724251 , 0.02024073],\n",
       "       [0.34003672, 0.26134565, 0.29670554, 0.08337192, 0.01854014],\n",
       "       [0.3549058 , 0.29158244, 0.28603002, 0.05870101, 0.00878068],\n",
       "       [0.3736391 , 0.29208687, 0.27337313, 0.05399883, 0.00690219],\n",
       "       [0.24599251, 0.23275527, 0.3541326 , 0.11754657, 0.04957311],\n",
       "       [0.27744174, 0.22426778, 0.34556213, 0.11067207, 0.04205634],\n",
       "       [0.22195794, 0.26750764, 0.37343043, 0.10421793, 0.03288611],\n",
       "       [0.22334674, 0.27952796, 0.36065865, 0.1186585 , 0.01780811],\n",
       "       [0.5229349 , 0.22502452, 0.19509155, 0.04250733, 0.01444168],\n",
       "       [0.52591366, 0.22199042, 0.18906343, 0.05170693, 0.01132548],\n",
       "       [0.44623193, 0.26057857, 0.21645962, 0.0500822 , 0.02664771],\n",
       "       [0.41215885, 0.26224953, 0.24817753, 0.05724855, 0.02016549],\n",
       "       [0.38825643, 0.26196513, 0.2804589 , 0.0544098 , 0.01490974],\n",
       "       [0.41073698, 0.29060766, 0.23125394, 0.05534397, 0.01205751],\n",
       "       [0.2526619 , 0.24590246, 0.37433618, 0.10683175, 0.02026764],\n",
       "       [0.37761244, 0.2614601 , 0.26904425, 0.07553369, 0.01634962],\n",
       "       [0.3395177 , 0.30151185, 0.30200642, 0.04133982, 0.01562422],\n",
       "       [0.38227016, 0.28183937, 0.26355174, 0.05346928, 0.01886949],\n",
       "       [0.4040705 , 0.29753622, 0.23682885, 0.0458391 , 0.01572529],\n",
       "       [0.31169647, 0.2753825 , 0.3236113 , 0.06898554, 0.02032422],\n",
       "       [0.28567466, 0.2006556 , 0.34847373, 0.13456762, 0.03062852],\n",
       "       [0.32462576, 0.23368587, 0.3125259 , 0.10491317, 0.02424937],\n",
       "       [0.25915965, 0.2284233 , 0.33697537, 0.14096002, 0.03448162],\n",
       "       [0.24065164, 0.22314213, 0.37484235, 0.1207789 , 0.04058506],\n",
       "       [0.30313715, 0.26235268, 0.32167304, 0.07762165, 0.03521552],\n",
       "       [0.33450162, 0.2575514 , 0.31284663, 0.0714668 , 0.02363354],\n",
       "       [0.21310936, 0.27611554, 0.38465583, 0.09685788, 0.02926134],\n",
       "       [0.26428145, 0.2855088 , 0.32891354, 0.09710123, 0.02419499],\n",
       "       [0.38229588, 0.2972184 , 0.24762847, 0.04925505, 0.02360217],\n",
       "       [0.43407288, 0.30295405, 0.20156327, 0.04321734, 0.01819235],\n",
       "       [0.3410164 , 0.24040028, 0.30786604, 0.09074195, 0.01997535],\n",
       "       [0.3083067 , 0.23267843, 0.33759075, 0.10394704, 0.0174771 ],\n",
       "       [0.21125396, 0.20889904, 0.42249608, 0.10478073, 0.05257028],\n",
       "       [0.20736337, 0.20977722, 0.4637285 , 0.09659521, 0.0225357 ],\n",
       "       [0.37914985, 0.25943068, 0.24602202, 0.07592721, 0.03947022],\n",
       "       [0.3160765 , 0.25767425, 0.29051673, 0.10478564, 0.0309469 ],\n",
       "       [0.15409112, 0.26300374, 0.47675633, 0.09574569, 0.01040306],\n",
       "       [0.16690738, 0.25339973, 0.43328547, 0.10473384, 0.04167359],\n",
       "       [0.30151835, 0.28823626, 0.31215757, 0.08166612, 0.01642172],\n",
       "       [0.31641597, 0.28211394, 0.3114821 , 0.07918546, 0.01080258],\n",
       "       [0.26716748, 0.25152826, 0.33773765, 0.11437759, 0.02918908],\n",
       "       [0.34007585, 0.2623555 , 0.2888091 , 0.0911346 , 0.0176249 ],\n",
       "       [0.2190052 , 0.21637928, 0.45537308, 0.08717649, 0.02206596],\n",
       "       [0.22867577, 0.23522745, 0.40192246, 0.09498318, 0.03919108],\n",
       "       [0.39291796, 0.24153762, 0.25885275, 0.0750464 , 0.03164534],\n",
       "       [0.4290547 , 0.24829562, 0.2426426 , 0.05902982, 0.02097726],\n",
       "       [0.19280726, 0.24008471, 0.39296523, 0.12587404, 0.0482688 ],\n",
       "       [0.2106726 , 0.2574861 , 0.4019168 , 0.11057933, 0.01934524],\n",
       "       [0.2887799 , 0.2955955 , 0.34287578, 0.06217364, 0.01057513],\n",
       "       [0.32388115, 0.25818732, 0.33620805, 0.06946475, 0.01225876],\n",
       "       [0.2558686 , 0.2833188 , 0.34426585, 0.0878999 , 0.02864692],\n",
       "       [0.27774677, 0.26681638, 0.338688  , 0.10008507, 0.01666379],\n",
       "       [0.53657997, 0.24374579, 0.15453042, 0.05093296, 0.0142109 ],\n",
       "       [0.49607503, 0.27311182, 0.17702283, 0.04271197, 0.01107832],\n",
       "       [0.22651817, 0.24993394, 0.38316712, 0.11208518, 0.02829562],\n",
       "       [0.26649693, 0.2583477 , 0.36652452, 0.09307343, 0.01555736],\n",
       "       [0.34356457, 0.3327001 , 0.26333365, 0.04333574, 0.01706588],\n",
       "       [0.3128883 , 0.3230056 , 0.30639648, 0.05019208, 0.00751761],\n",
       "       [0.2320448 , 0.24027915, 0.41366315, 0.09880044, 0.01521253],\n",
       "       [0.20873347, 0.23058452, 0.43921286, 0.10961369, 0.0118555 ],\n",
       "       [0.24609521, 0.25229442, 0.36977422, 0.1046263 , 0.02720983],\n",
       "       [0.25915405, 0.2597307 , 0.38425344, 0.08399355, 0.0128683 ],\n",
       "       [0.2533653 , 0.2888056 , 0.33135206, 0.09890123, 0.02757578],\n",
       "       [0.36869383, 0.2999057 , 0.2562736 , 0.0579093 , 0.01721762]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f([model2_input, 1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
